{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "DKymKLSw7lrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBqGHHnZhyH9",
        "outputId": "3af7950b-ddd5-411a-8284-f21c68e8ec7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mt-exercise-03' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JeanKesselring/mt-exercise-03"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-03 && ./scripts/install_packages.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl_daY80aNFv",
        "outputId": "36523cf0-496b-4efb-cf47-e0d40ac76bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make sure this script is executed AFTER you have activated a virtualenv\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0+cu118)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacremoses) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sacremoses) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=a799cce0e4a1e5dc633dda7e5277a6ce0ed7a5a443a42bd260b5489848e6c507\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n",
            "Cloning into './scripts/../tools/moses-scripts'...\n",
            "remote: Enumerating objects: 147096, done.\u001b[K\n",
            "remote: Total 147096 (delta 0), reused 0 (delta 0), pack-reused 147096\u001b[K\n",
            "Receiving objects: 100% (147096/147096), 129.65 MiB | 23.02 MiB/s, done.\n",
            "Resolving deltas: 100% (113689/113689), done.\n",
            "Cloning into './scripts/../tools/pytorch-examples'...\n",
            "remote: Enumerating objects: 3845, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 3845 (delta 14), reused 31 (delta 5), pack-reused 3794\u001b[K\n",
            "Receiving objects: 100% (3845/3845), 41.09 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (1903/1903), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-03 && ls tools/pytorch-examples/word_language_model/data/wikitext-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZXRELqEcdXd",
        "outputId": "49478968-c750-482c-ad0b-bee43ae1ffc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README\ttest.txt  train.txt  valid.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their part:"
      ],
      "metadata": {
        "id": "DrJUIHtxcZgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-03 && ./scripts/download_data.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ll_v76aTOu",
        "outputId": "a9b6008f-5e56-4e78-ab18-ef28c85ce9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-12 10:07:46--  https://www.gutenberg.org/files/52521/52521-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 522843 (511K) [text/plain]\n",
            "Saving to: ‘52521-0.txt’\n",
            "\n",
            "52521-0.txt         100%[===================>] 510.59K  1.65MB/s    in 0.3s    \n",
            "\n",
            "2023-04-12 10:07:47 (1.65 MB/s) - ‘52521-0.txt’ saved [522843/522843]\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "DEBUG:root:Namespace(vocab_size=5000, tokenize=True, unk_string='<unk>', lang='en', sent_tokenize=True, language='english')\n",
            "DEBUG:root:Vocabulary size before/after/max_allowed = 6206/5000/5000\n",
            "DEBUG:root:Time taken: 1.481143 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = '''#! /bin/bash\n",
        "\n",
        "scripts=$(dirname \"$0\")\n",
        "base=$(realpath $scripts/..)\n",
        "\n",
        "models=$base/models\n",
        "data=$base/data\n",
        "tools=$base/tools\n",
        "\n",
        "mkdir -p $models\n",
        "\n",
        "num_threads=4\n",
        "device=\"\"\n",
        "\n",
        "SECONDS=0\n",
        "\n",
        "(cd $tools/pytorch-examples/word_language_model &&\n",
        "    CUDA_VISIBLE_DEVICES=$device OMP_NUM_THREADS=$num_threads python main.py --data $data/seinfeld \\\n",
        "        --epochs 40 \\\n",
        "        --log-interval 100 \\\n",
        "        --emsize 200 --nhid 200 --dropout 0.5 --tied \\\n",
        "        --save $models/model.pt\n",
        ")\n",
        "\n",
        "echo \"time taken:\"\n",
        "echo \"$SECONDS seconds\"'''\n",
        "\n",
        "with open(\"mt-exercise-03/scripts/train.sh\",\"w\")as file:\n",
        "  file.write(txt)"
      ],
      "metadata": {
        "id": "IOeT4Vz683Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-03 && ./scripts/train.sh"
      ],
      "metadata": {
        "id": "JN8T0ARqatE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636c3d59-bf3e-44aa-afe8-62c2f18704b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   100/  186 batches | lr 20.00 | ms/batch 153.03 | loss  6.09 | ppl   439.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 28.56s | valid loss  4.85 | valid ppl   127.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   100/  186 batches | lr 20.00 | ms/batch 157.84 | loss  4.73 | ppl   113.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 29.06s | valid loss  4.35 | valid ppl    77.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   100/  186 batches | lr 20.00 | ms/batch 150.13 | loss  4.40 | ppl    81.58\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 28.08s | valid loss  4.15 | valid ppl    63.46\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   100/  186 batches | lr 20.00 | ms/batch 149.14 | loss  4.24 | ppl    69.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 27.95s | valid loss  4.06 | valid ppl    57.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   100/  186 batches | lr 20.00 | ms/batch 150.79 | loss  4.14 | ppl    62.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 28.33s | valid loss  3.99 | valid ppl    54.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   100/  186 batches | lr 20.00 | ms/batch 160.57 | loss  4.06 | ppl    58.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 29.28s | valid loss  3.95 | valid ppl    51.89\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   100/  186 batches | lr 20.00 | ms/batch 149.14 | loss  4.01 | ppl    55.15\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 28.06s | valid loss  3.92 | valid ppl    50.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   100/  186 batches | lr 20.00 | ms/batch 148.79 | loss  3.97 | ppl    52.72\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 28.08s | valid loss  3.89 | valid ppl    49.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   100/  186 batches | lr 20.00 | ms/batch 151.84 | loss  3.92 | ppl    50.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 28.59s | valid loss  3.87 | valid ppl    47.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   100/  186 batches | lr 20.00 | ms/batch 163.11 | loss  3.89 | ppl    49.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 29.68s | valid loss  3.86 | valid ppl    47.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |   100/  186 batches | lr 20.00 | ms/batch 150.04 | loss  3.86 | ppl    47.49\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 28.24s | valid loss  3.85 | valid ppl    46.77\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |   100/  186 batches | lr 20.00 | ms/batch 150.27 | loss  3.84 | ppl    46.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 28.41s | valid loss  3.83 | valid ppl    46.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |   100/  186 batches | lr 20.00 | ms/batch 148.16 | loss  3.81 | ppl    45.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 28.08s | valid loss  3.83 | valid ppl    46.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |   100/  186 batches | lr 5.00 | ms/batch 160.77 | loss  3.73 | ppl    41.86\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 29.44s | valid loss  3.78 | valid ppl    43.93\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |   100/  186 batches | lr 5.00 | ms/batch 151.81 | loss  3.69 | ppl    40.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 28.51s | valid loss  3.77 | valid ppl    43.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |   100/  186 batches | lr 5.00 | ms/batch 149.33 | loss  3.67 | ppl    39.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 28.23s | valid loss  3.77 | valid ppl    43.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |   100/  186 batches | lr 5.00 | ms/batch 149.96 | loss  3.65 | ppl    38.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 28.44s | valid loss  3.77 | valid ppl    43.29\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |   100/  186 batches | lr 5.00 | ms/batch 163.06 | loss  3.64 | ppl    38.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 29.65s | valid loss  3.76 | valid ppl    43.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |   100/  186 batches | lr 5.00 | ms/batch 150.25 | loss  3.63 | ppl    37.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 28.36s | valid loss  3.77 | valid ppl    43.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |   100/  186 batches | lr 1.25 | ms/batch 146.95 | loss  3.61 | ppl    36.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 27.90s | valid loss  3.75 | valid ppl    42.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  21 |   100/  186 batches | lr 1.25 | ms/batch 149.45 | loss  3.59 | ppl    36.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time: 28.05s | valid loss  3.75 | valid ppl    42.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |   100/  186 batches | lr 1.25 | ms/batch 155.90 | loss  3.59 | ppl    36.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time: 28.79s | valid loss  3.75 | valid ppl    42.61\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |   100/  186 batches | lr 1.25 | ms/batch 147.81 | loss  3.59 | ppl    36.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time: 27.68s | valid loss  3.75 | valid ppl    42.67\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |   100/  186 batches | lr 0.31 | ms/batch 144.84 | loss  3.58 | ppl    35.75\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time: 27.25s | valid loss  3.75 | valid ppl    42.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |   100/  186 batches | lr 0.31 | ms/batch 147.54 | loss  3.58 | ppl    35.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time: 27.52s | valid loss  3.75 | valid ppl    42.51\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |   100/  186 batches | lr 0.31 | ms/batch 146.61 | loss  3.57 | ppl    35.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time: 27.56s | valid loss  3.75 | valid ppl    42.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |   100/  186 batches | lr 0.31 | ms/batch 149.65 | loss  3.57 | ppl    35.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time: 28.49s | valid loss  3.75 | valid ppl    42.47\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |   100/  186 batches | lr 0.31 | ms/batch 147.76 | loss  3.57 | ppl    35.60\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time: 27.85s | valid loss  3.75 | valid ppl    42.45\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |   100/  186 batches | lr 0.31 | ms/batch 147.55 | loss  3.57 | ppl    35.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time: 27.84s | valid loss  3.75 | valid ppl    42.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |   100/  186 batches | lr 0.31 | ms/batch 147.80 | loss  3.57 | ppl    35.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 27.69s | valid loss  3.75 | valid ppl    42.41\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  31 |   100/  186 batches | lr 0.31 | ms/batch 147.07 | loss  3.57 | ppl    35.56\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time: 27.52s | valid loss  3.75 | valid ppl    42.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |   100/  186 batches | lr 0.08 | ms/batch 157.94 | loss  3.57 | ppl    35.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time: 28.97s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |   100/  186 batches | lr 0.02 | ms/batch 146.43 | loss  3.57 | ppl    35.62\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time: 27.47s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |   100/  186 batches | lr 0.00 | ms/batch 147.52 | loss  3.57 | ppl    35.43\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time: 27.67s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |   100/  186 batches | lr 0.00 | ms/batch 148.28 | loss  3.56 | ppl    35.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time: 27.93s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |   100/  186 batches | lr 0.00 | ms/batch 146.74 | loss  3.57 | ppl    35.48\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time: 27.67s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |   100/  186 batches | lr 0.00 | ms/batch 155.87 | loss  3.57 | ppl    35.34\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time: 28.48s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |   100/  186 batches | lr 0.00 | ms/batch 147.70 | loss  3.56 | ppl    35.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time: 27.90s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |   100/  186 batches | lr 0.00 | ms/batch 147.96 | loss  3.57 | ppl    35.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time: 27.46s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |   100/  186 batches | lr 0.00 | ms/batch 141.99 | loss  3.57 | ppl    35.40\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 27.21s | valid loss  3.75 | valid ppl    42.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "=========================================================================================\n",
            "| End of training | test loss  3.71 | test ppl    40.99\n",
            "=========================================================================================\n",
            "time taken:\n",
            "1133 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mt-exercise-03 && ./scripts/generate.sh"
      ],
      "metadata": {
        "id": "MnhRpYgJa3Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfa8528-0507-439b-bb3e-d10c00981f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Generated 0/100 words\n"
          ]
        }
      ]
    }
  ]
}